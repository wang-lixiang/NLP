{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回归问题主要关注确定一个唯一的因变量（需要预测的值）和一个或多个数值型自变量（预测变量）之间的关系。  \n",
    "需要预测的值：即目标变量，target，y，连续值  \n",
    "预测变量：影响目标变量的因素，predictors，X1...XN，可以是连续值也可以是离散值   \n",
    "之间的关系：即模型，model，是我们要求解的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 简单的线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y=a+bx，尽可能的拟合所有点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "人工智能算法要求的是最优解！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Img/4.png\" width=\"20%\" height=\"20%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最优解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual Value：真实值，即已知的y  \n",
    "Predicted value：预测值，是把已知的x带入到公式里面和猜出来的参数a,b计算得到的  \n",
    "Error：误差，预测值和真实值的差距  \n",
    "最优解：尽可能的找到一个模型使得整体的误差最小，整体的误差通常叫做损失Loss   \n",
    "Loss：整体的误差，loss通过损失函数loss function计算得到  \n",
    "*尽可能的使我们的Loss最小，得到的就是我们的最优解，也即此时的参数a,b最优*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于线性回归来说，采用的损失函数一般是MSE（Mean Squared Error)  \n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "MSE的取值越小，表示模型的预测结果越接近真实值，模型的预测精度越高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多元线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "事实上，影响结果的因素不止一个，这时x就从一个变成了n个"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y} = \\beta _0 + \\beta _1X\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于权重$\\beta_0,\\beta_1,....\\beta_n$，我们平时也可以用$w_0,w_1....w_n$来表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Img/5.png\" width=\"20%\" height=\"20%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y} = \\beta_0X_0 + \\beta_1X_1 + \\beta_2X_2 + \\beta_3X_3\n",
    "$$\n",
    "这里$X_0$始终为1，保持了可以让$X$向量，$\\beta$向量保持相乘的状态  \n",
    "$\\epsilon$是误差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单可表达为$y = W^TX + \\epsilon$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 深入理解回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回归简单来说就是“回归平均值”，但是这里的mean并不是把历史数值直接当作未来的预测值，而是会把期望值当作预测值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### （1）中心极限定理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讨论随机变量序列部分和分布渐近于正态分布的一类定理。指出了大量随机变量累积分布函数逐点收敛到正态分布的积累分布函数的条件。（相互独立）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习中我们假设误差符合均值为0，方差为定值的正态分布！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### （2）最大似然估计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于误差，我们需要知道构成误差的参数是多少，因此我们用这个来进行判断"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "L(\\Theta | x_1,...x_n) = f_\\Theta(x_1,...,x_n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "公式的前半部分是，已知n个样本，$\\Theta$出现的最大的可能性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "公式的后半部分是，已知$\\Theta$的情况下，有n个样本共同出现的总概率是什么"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytic solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.31037307],\n",
       "       [1.78719314],\n",
       "       [0.95046875],\n",
       "       [1.54303757],\n",
       "       [0.70979891],\n",
       "       [1.36923766],\n",
       "       [1.47085277],\n",
       "       [0.74125198],\n",
       "       [1.02884667],\n",
       "       [0.41761495],\n",
       "       [1.40709317],\n",
       "       [1.06138715],\n",
       "       [1.2933035 ],\n",
       "       [1.60555664],\n",
       "       [0.49410266],\n",
       "       [0.1809435 ],\n",
       "       [1.71373626],\n",
       "       [0.980783  ],\n",
       "       [0.87574307],\n",
       "       [1.12417382],\n",
       "       [1.30718547],\n",
       "       [1.3633192 ],\n",
       "       [0.82573681],\n",
       "       [1.29491029],\n",
       "       [1.28326399],\n",
       "       [0.45441405],\n",
       "       [0.85916647],\n",
       "       [0.45559981],\n",
       "       [1.80014115],\n",
       "       [0.82688179],\n",
       "       [0.67691659],\n",
       "       [1.47651517],\n",
       "       [1.65223125],\n",
       "       [0.01955917],\n",
       "       [1.84016271],\n",
       "       [0.67218682],\n",
       "       [0.22886488],\n",
       "       [1.03556243],\n",
       "       [0.72534732],\n",
       "       [0.53600493],\n",
       "       [0.76976911],\n",
       "       [0.50788729],\n",
       "       [0.8949049 ],\n",
       "       [0.32911806],\n",
       "       [1.39384468],\n",
       "       [1.55404908],\n",
       "       [1.95752141],\n",
       "       [1.34535485],\n",
       "       [0.03559763],\n",
       "       [0.97162387],\n",
       "       [1.17594113],\n",
       "       [0.49568395],\n",
       "       [1.92942742],\n",
       "       [1.56604854],\n",
       "       [1.65962614],\n",
       "       [0.28024977],\n",
       "       [1.60794611],\n",
       "       [0.4054872 ],\n",
       "       [0.52767629],\n",
       "       [1.35818502],\n",
       "       [1.98833206],\n",
       "       [0.17789341],\n",
       "       [1.1431403 ],\n",
       "       [1.65781088],\n",
       "       [0.73090962],\n",
       "       [0.5186441 ],\n",
       "       [1.22698311],\n",
       "       [1.12935997],\n",
       "       [0.20012654],\n",
       "       [1.41873175],\n",
       "       [0.55387914],\n",
       "       [1.60183976],\n",
       "       [1.61945305],\n",
       "       [0.82644337],\n",
       "       [1.78597302],\n",
       "       [1.99153905],\n",
       "       [1.91699365],\n",
       "       [1.94099878],\n",
       "       [0.94167113],\n",
       "       [0.81491383],\n",
       "       [0.0418953 ],\n",
       "       [0.32302328],\n",
       "       [1.50782374],\n",
       "       [0.70118615],\n",
       "       [1.50321568],\n",
       "       [1.33313266],\n",
       "       [1.50728992],\n",
       "       [0.63674243],\n",
       "       [0.42941494],\n",
       "       [1.6757122 ],\n",
       "       [1.51645342],\n",
       "       [1.84773239],\n",
       "       [0.86233096],\n",
       "       [0.76749374],\n",
       "       [0.57185851],\n",
       "       [0.16461614],\n",
       "       [0.68133213],\n",
       "       [1.12815219],\n",
       "       [1.70986532],\n",
       "       [0.9235404 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 解析解求解模型的方法\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = 2 * np.random.rand(100,1)\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.68981647],\n",
       "       [12.63264215],\n",
       "       [ 9.1369731 ],\n",
       "       [11.28925867],\n",
       "       [ 8.22867941],\n",
       "       [11.45758085],\n",
       "       [10.38368075],\n",
       "       [ 9.4378655 ],\n",
       "       [ 7.36816142],\n",
       "       [ 6.44410298],\n",
       "       [ 9.74532616],\n",
       "       [ 8.3671922 ],\n",
       "       [ 9.27862706],\n",
       "       [11.84189594],\n",
       "       [ 7.55813143],\n",
       "       [ 5.60579218],\n",
       "       [12.1756195 ],\n",
       "       [10.36351686],\n",
       "       [ 9.02881559],\n",
       "       [ 9.77455245],\n",
       "       [10.85386711],\n",
       "       [10.88280994],\n",
       "       [ 9.10150921],\n",
       "       [10.3159079 ],\n",
       "       [ 8.65308031],\n",
       "       [ 6.59606404],\n",
       "       [ 7.27907483],\n",
       "       [ 5.90733345],\n",
       "       [13.4186884 ],\n",
       "       [ 7.60847473],\n",
       "       [ 7.30635753],\n",
       "       [ 9.42208017],\n",
       "       [12.06822815],\n",
       "       [ 4.7778266 ],\n",
       "       [12.96607459],\n",
       "       [ 7.94591651],\n",
       "       [ 4.8991991 ],\n",
       "       [ 7.74745472],\n",
       "       [ 8.07157791],\n",
       "       [ 7.69106044],\n",
       "       [ 9.05009652],\n",
       "       [ 7.32271263],\n",
       "       [ 8.04967839],\n",
       "       [ 6.23293178],\n",
       "       [10.52224984],\n",
       "       [10.82354417],\n",
       "       [14.83962971],\n",
       "       [10.78414631],\n",
       "       [ 4.04088614],\n",
       "       [ 9.03750637],\n",
       "       [ 9.82733579],\n",
       "       [ 5.72546617],\n",
       "       [12.38226768],\n",
       "       [10.48730773],\n",
       "       [12.5467159 ],\n",
       "       [ 5.29998304],\n",
       "       [12.01702073],\n",
       "       [ 6.00188264],\n",
       "       [ 7.76470857],\n",
       "       [ 9.46278365],\n",
       "       [14.12530824],\n",
       "       [ 5.48519284],\n",
       "       [ 9.23813385],\n",
       "       [10.916717  ],\n",
       "       [ 9.16460229],\n",
       "       [ 7.32340609],\n",
       "       [10.37839762],\n",
       "       [10.23936138],\n",
       "       [ 5.99053698],\n",
       "       [11.80335633],\n",
       "       [ 6.78504541],\n",
       "       [10.8003098 ],\n",
       "       [12.62259156],\n",
       "       [ 6.24169815],\n",
       "       [12.88751002],\n",
       "       [13.46302113],\n",
       "       [10.97968055],\n",
       "       [12.04264493],\n",
       "       [ 8.49315882],\n",
       "       [ 9.11748544],\n",
       "       [ 4.44179294],\n",
       "       [ 6.40920095],\n",
       "       [11.66629695],\n",
       "       [ 6.85122885],\n",
       "       [10.20045149],\n",
       "       [ 8.95863168],\n",
       "       [10.85372121],\n",
       "       [ 5.32025696],\n",
       "       [ 6.58769408],\n",
       "       [13.53429035],\n",
       "       [11.00112895],\n",
       "       [11.26181577],\n",
       "       [ 8.30448515],\n",
       "       [ 8.82906029],\n",
       "       [ 7.29071003],\n",
       "       [ 5.37254156],\n",
       "       [ 9.3480012 ],\n",
       "       [ 8.8215438 ],\n",
       "       [12.26060451],\n",
       "       [ 7.55023975]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模拟y作为真实的数据，也就是y_hat + error\n",
    "y = 5 + 4*X + np.random.randn(100,1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.31037307],\n",
       "       [1.        , 1.78719314],\n",
       "       [1.        , 0.95046875],\n",
       "       [1.        , 1.54303757],\n",
       "       [1.        , 0.70979891],\n",
       "       [1.        , 1.36923766],\n",
       "       [1.        , 1.47085277],\n",
       "       [1.        , 0.74125198],\n",
       "       [1.        , 1.02884667],\n",
       "       [1.        , 0.41761495],\n",
       "       [1.        , 1.40709317],\n",
       "       [1.        , 1.06138715],\n",
       "       [1.        , 1.2933035 ],\n",
       "       [1.        , 1.60555664],\n",
       "       [1.        , 0.49410266],\n",
       "       [1.        , 0.1809435 ],\n",
       "       [1.        , 1.71373626],\n",
       "       [1.        , 0.980783  ],\n",
       "       [1.        , 0.87574307],\n",
       "       [1.        , 1.12417382],\n",
       "       [1.        , 1.30718547],\n",
       "       [1.        , 1.3633192 ],\n",
       "       [1.        , 0.82573681],\n",
       "       [1.        , 1.29491029],\n",
       "       [1.        , 1.28326399],\n",
       "       [1.        , 0.45441405],\n",
       "       [1.        , 0.85916647],\n",
       "       [1.        , 0.45559981],\n",
       "       [1.        , 1.80014115],\n",
       "       [1.        , 0.82688179],\n",
       "       [1.        , 0.67691659],\n",
       "       [1.        , 1.47651517],\n",
       "       [1.        , 1.65223125],\n",
       "       [1.        , 0.01955917],\n",
       "       [1.        , 1.84016271],\n",
       "       [1.        , 0.67218682],\n",
       "       [1.        , 0.22886488],\n",
       "       [1.        , 1.03556243],\n",
       "       [1.        , 0.72534732],\n",
       "       [1.        , 0.53600493],\n",
       "       [1.        , 0.76976911],\n",
       "       [1.        , 0.50788729],\n",
       "       [1.        , 0.8949049 ],\n",
       "       [1.        , 0.32911806],\n",
       "       [1.        , 1.39384468],\n",
       "       [1.        , 1.55404908],\n",
       "       [1.        , 1.95752141],\n",
       "       [1.        , 1.34535485],\n",
       "       [1.        , 0.03559763],\n",
       "       [1.        , 0.97162387],\n",
       "       [1.        , 1.17594113],\n",
       "       [1.        , 0.49568395],\n",
       "       [1.        , 1.92942742],\n",
       "       [1.        , 1.56604854],\n",
       "       [1.        , 1.65962614],\n",
       "       [1.        , 0.28024977],\n",
       "       [1.        , 1.60794611],\n",
       "       [1.        , 0.4054872 ],\n",
       "       [1.        , 0.52767629],\n",
       "       [1.        , 1.35818502],\n",
       "       [1.        , 1.98833206],\n",
       "       [1.        , 0.17789341],\n",
       "       [1.        , 1.1431403 ],\n",
       "       [1.        , 1.65781088],\n",
       "       [1.        , 0.73090962],\n",
       "       [1.        , 0.5186441 ],\n",
       "       [1.        , 1.22698311],\n",
       "       [1.        , 1.12935997],\n",
       "       [1.        , 0.20012654],\n",
       "       [1.        , 1.41873175],\n",
       "       [1.        , 0.55387914],\n",
       "       [1.        , 1.60183976],\n",
       "       [1.        , 1.61945305],\n",
       "       [1.        , 0.82644337],\n",
       "       [1.        , 1.78597302],\n",
       "       [1.        , 1.99153905],\n",
       "       [1.        , 1.91699365],\n",
       "       [1.        , 1.94099878],\n",
       "       [1.        , 0.94167113],\n",
       "       [1.        , 0.81491383],\n",
       "       [1.        , 0.0418953 ],\n",
       "       [1.        , 0.32302328],\n",
       "       [1.        , 1.50782374],\n",
       "       [1.        , 0.70118615],\n",
       "       [1.        , 1.50321568],\n",
       "       [1.        , 1.33313266],\n",
       "       [1.        , 1.50728992],\n",
       "       [1.        , 0.63674243],\n",
       "       [1.        , 0.42941494],\n",
       "       [1.        , 1.6757122 ],\n",
       "       [1.        , 1.51645342],\n",
       "       [1.        , 1.84773239],\n",
       "       [1.        , 0.86233096],\n",
       "       [1.        , 0.76749374],\n",
       "       [1.        , 0.57185851],\n",
       "       [1.        , 0.16461614],\n",
       "       [1.        , 0.68133213],\n",
       "       [1.        , 1.12815219],\n",
       "       [1.        , 1.70986532],\n",
       "       [1.        , 0.9235404 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 为了求解W0截距项，我们给X矩阵一开始加上一列全为1的X0\n",
    "X_b = np.c_[np.ones((100,1)),X]\n",
    "X_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.64353909],\n",
       "       [4.2958282 ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实现解析解的公式来求解θ\n",
    "# 已知对应的x,y的值，散布在整个区间内，我们对这些数据进行拟合，得到一条尽可能满足点的线，θ就是参数\n",
    "θ = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "θ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 2.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用模型去做预测\n",
    "X_new = np.array([[0],[2]])\n",
    "X_new_b = np.c_[np.ones((2,1)),X_new]\n",
    "\n",
    "X_new_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.64353909],\n",
       "       [13.23519549]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = X_new_b.dot(θ)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "E_opencv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
