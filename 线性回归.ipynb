{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回归问题主要关注确定一个唯一的因变量（需要预测的值）和一个或多个数值型自变量（预测变量）之间的关系。  \n",
    "需要预测的值：即目标变量，target，y，连续值  \n",
    "预测变量：影响目标变量的因素，predictors，X1...XN，可以是连续值也可以是离散值   \n",
    "之间的关系：即模型，model，是我们要求解的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 简单的线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y=a+bx，尽可能的拟合所有点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "人工智能算法要求的是最优解！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Img/4.png\" width=\"20%\" height=\"20%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最优解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual Value：真实值，即已知的y  \n",
    "Predicted value：预测值，是把已知的x带入到公式里面和猜出来的参数a,b计算得到的  \n",
    "Error：误差，预测值和真实值的差距  \n",
    "最优解：尽可能的找到一个模型使得整体的误差最小，整体的误差通常叫做损失Loss   \n",
    "Loss：整体的误差，loss通过损失函数loss function计算得到  \n",
    "*尽可能的使我们的Loss最小，得到的就是我们的最优解，也即此时的参数a,b最优*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于线性回归来说，采用的损失函数一般是MSE（Mean Squared Error)  \n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "MSE的取值越小，表示模型的预测结果越接近真实值，模型的预测精度越高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多元线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "事实上，影响结果的因素不止一个，这时x就从一个变成了n个"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y} = \\beta _0 + \\beta _1X\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于权重$\\beta_0,\\beta_1,....\\beta_n$，我们平时也可以用$w_0,w_1....w_n$来表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Img/5.png\" width=\"20%\" height=\"20%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y} = \\beta_0X_0 + \\beta_1X_1 + \\beta_2X_2 + \\beta_3X_3\n",
    "$$\n",
    "这里$X_0$始终为1，保持了可以让$X$向量，$\\beta$向量保持相乘的状态  \n",
    "$\\epsilon$是误差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单可表达为$y = W^TX + \\epsilon$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 深入理解回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回归简单来说就是“回归平均值”，但是这里的mean并不是把历史数值直接当作未来的预测值，而是会把期望值当作预测值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### （1）中心极限定理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讨论随机变量序列部分和分布渐近于正态分布的一类定理。指出了大量随机变量累积分布函数逐点收敛到正态分布的积累分布函数的条件。（相互独立）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习中我们假设误差符合均值为0，方差为定值的正态分布！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### （2）最大似然估计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于误差，我们需要知道构成误差的参数是多少，因此我们用这个来进行判断"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "L(\\Theta | x_1,...x_n) = f_\\Theta(x_1,...,x_n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "公式的前半部分是，已知n个样本，$\\Theta$出现的最大的可能性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "公式的后半部分是，已知$\\Theta$的情况下，有n个样本共同出现的总概率是什么"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
