{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4bbf6e8",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274ce801",
   "metadata": {},
   "source": [
    "人类的认识过程是一个**分类**的过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ce59e",
   "metadata": {},
   "source": [
    "### 大牛"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65b5f9a",
   "metadata": {},
   "source": [
    "* Hinton: 反向传播（BP)可以应用到神经网络与深度学习\n",
    "* LeCun：CNN之父\n",
    "* Bengio: 语言基础"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324b6929",
   "metadata": {},
   "source": [
    "### NUL 理解自然语言"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebe199d",
   "metadata": {},
   "source": [
    "* 分类任务：文本分类/情感分析\n",
    "* 序列标注：分词/语义标注\n",
    "* 句子关系判断：文本匹配/QA（就是机器该如何回答你提出的问题）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bb2f43",
   "metadata": {},
   "source": [
    "### NLG 生成自然语言"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68477ba2",
   "metadata": {},
   "source": [
    "* 对话回复生成\n",
    "* 机器翻译\n",
    "* 生成式文本摘要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c86490",
   "metadata": {},
   "source": [
    "### 语言模型：计算一个语言序列的概率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44c0f73",
   "metadata": {},
   "source": [
    "判断一个语言序列是否是正常语句。  \n",
    "P（我是中国人）> P（人是我中国）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fa583e",
   "metadata": {},
   "source": [
    "#### 计算模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fedc5f3",
   "metadata": {},
   "source": [
    "* 链式法则：P（w1....wn)=P(w1).P(w2|w1)...P(wn|w1...wn-1)\n",
    "    * 一般不采用\n",
    "* Markov假设：某个词出现的概率只依赖于前面的有限个词（如K个词）  \n",
    "    * P(wi|w1...wi-1)=P(wi|wi-k...wi-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775fa4d3",
   "metadata": {},
   "source": [
    "#### N-gram语言模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6e8b36",
   "metadata": {},
   "source": [
    "在Markov假设下，即假设当前词出现的频率只依赖于前n-1个词   \n",
    "无法捕捉词与词之间的相似性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc446fc",
   "metadata": {},
   "source": [
    "#### 深度学习模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60614f61",
   "metadata": {},
   "source": [
    "* NNLM（神经网络）\n",
    "    * 和N-gram类似，NNLM也假设当前词仅依赖于前n-1个词\n",
    "    * 给定前n-1个词，得到这个词的概率，概率和为1，实质上是一个分类\n",
    "* word2vec\n",
    "    * CBOW\n",
    "    * skip-gram\n",
    "* EMLO\n",
    "* transformer\n",
    "    * self-attention(自注意力）：让机器注意到每个词向量之间的相关性，有侧重地进行翻译，模拟人类理解的过程\n",
    "* GPT3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b614b303",
   "metadata": {},
   "source": [
    "### 中文分词"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5319a8a9",
   "metadata": {},
   "source": [
    "将连续的字序列按照一定的规范重新组合成词序列的过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d2cf8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94834e0d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee5cfae4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
